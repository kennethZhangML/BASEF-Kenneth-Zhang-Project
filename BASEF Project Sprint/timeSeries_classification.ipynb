{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "c756aee152fae344a2a35059eabe72da58ce5d575e2de6640d02fbde631497fe"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers, initializers, activations\n",
    "from tensorflow.keras.applications import resnet, resnet50\n",
    "from tensorflow.keras.preprocessing import timeseries_dataset_from_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpatient1 = pd.read_csv(\"patient1.csv\")\n",
    "dfpatient2 = pd.read_csv(\"patient2.csv\")\n",
    "dfpatient3 = pd.read_csv(\"patient3.csv\")\n",
    "dfpatient4 = pd.read_csv(\"patient4.csv\")\n",
    "\n",
    "df_list = [dfpatient1, dfpatient2, dfpatient3, dfpatient4]\n",
    "df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "df_train = df[['Fz',\t'Cz',\t'Pz',\t'Oz',\t'P3',\t'P4',\t'PO7',\t'PO8']]\n",
    "df_targets = df[['y_stim']]\n",
    "\n",
    "num_classes = len(np.unique(df_targets[['y_stim']]))\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((1390816, 8), (1390816, 1))"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df_train.shape, df_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(6053, 200, 8) (6053, 1)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def create_dataset(X, y, time_steps=1, step=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(0, len(X) - time_steps, step):\n",
    "        v = X.iloc[i:(i + time_steps)].values\n",
    "        labels = y.iloc[i: i + time_steps]\n",
    "        Xs.append(v)\n",
    "        ys.append(stats.mode(labels)[0][0])\n",
    "    return np.array(Xs), np.array(ys).reshape(-1, 1)\n",
    "\n",
    "TIME_STEPS = 200\n",
    "STEP = 40\n",
    "\n",
    "X_train, y_train = create_dataset(\n",
    "    df_train[['Fz',\t'Cz',\t'Pz',\t'Oz',\t'P3',\t'P4',\t'PO7',\t'PO8']][1801:244102],\n",
    "    df_targets[1801:244102], TIME_STEPS, STEP)\n",
    "\n",
    "X_test, y_test = create_dataset(\n",
    "    df_train[['Fz',\t'Cz',\t'Pz',\t'Oz',\t'P3',\t'P4',\t'PO7',\t'PO8']][244102:344102],\n",
    "    df_targets[244102:344102], TIME_STEPS, STEP)\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "'''This part can be utilized for predicting the y_values which indicated whether the patient was\n",
    "visualizing or tested on non-target or target stimulus, in order to allow us to understand the reaction in EEG wavelengths'''\n",
    "\n",
    "#enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "#enc = enc.fit(y_train)\n",
    "#y_train = enc.transform(y_train)\n",
    "#y_test = enc.transform(y_test)\n",
    "\n",
    "#y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Bidirectional(keras.layers.LSTM(128, input_shape=[X_train.shape[1], X_train.shape[2]])))\n",
    "model.add(keras.layers.Dropout(rate =  0.5))\n",
    "model.add(keras.layers.Dense(128, activation = 'sigmoid'))\n",
    "model.add(keras.layers.Dense(y_train.shape[1], activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "133/133 [==============================] - 15s 113ms/step - loss: 0.0000e+00 - acc: 0.9958 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 2/20\n",
      "133/133 [==============================] - 19s 142ms/step - loss: 0.0000e+00 - acc: 0.9958 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 3/20\n",
      "133/133 [==============================] - 19s 140ms/step - loss: 0.0000e+00 - acc: 0.9969 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 4/20\n",
      "133/133 [==============================] - 30s 225ms/step - loss: 0.0000e+00 - acc: 0.9950 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 5/20\n",
      "133/133 [==============================] - 30s 223ms/step - loss: 0.0000e+00 - acc: 0.9972 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "133/133 [==============================] - 30s 224ms/step - loss: 0.0000e+00 - acc: 0.9960 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "133/133 [==============================] - 29s 219ms/step - loss: 0.0000e+00 - acc: 0.9962 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "133/133 [==============================] - 29s 220ms/step - loss: 0.0000e+00 - acc: 0.9960 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "133/133 [==============================] - 30s 222ms/step - loss: 0.0000e+00 - acc: 0.9960 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "133/133 [==============================] - 30s 223ms/step - loss: 0.0000e+00 - acc: 0.9950 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "133/133 [==============================] - 29s 215ms/step - loss: 0.0000e+00 - acc: 0.9967 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "133/133 [==============================] - 29s 218ms/step - loss: 0.0000e+00 - acc: 0.9969 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "133/133 [==============================] - 27s 201ms/step - loss: 0.0000e+00 - acc: 0.9976 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "133/133 [==============================] - 30s 222ms/step - loss: 0.0000e+00 - acc: 0.9950 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "133/133 [==============================] - 28s 212ms/step - loss: 0.0000e+00 - acc: 0.9962 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "133/133 [==============================] - 27s 204ms/step - loss: 0.0000e+00 - acc: 0.9972 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "133/133 [==============================] - 28s 211ms/step - loss: 0.0000e+00 - acc: 0.9950 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "133/133 [==============================] - 28s 208ms/step - loss: 0.0000e+00 - acc: 0.9960 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "133/133 [==============================] - 29s 219ms/step - loss: 0.0000e+00 - acc: 0.9967 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "133/133 [==============================] - 29s 220ms/step - loss: 0.0000e+00 - acc: 0.9974 - val_loss: 0.0000e+00 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 20,\n",
    "batch_size = 32, validation_split = 0.3, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "78/78 [==============================] - 5s 67ms/step - loss: 0.0000e+00 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_test)"
   ]
  }
 ]
}